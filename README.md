# Snake avec Q-Learning

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![UV](https://img.shields.io/badge/uv-managed-blueviolet.svg)](https://github.com/astral-sh/uv)

Projet d'apprentissage par renforcement : un agent apprend Ã  jouer au jeu Snake en utilisant l'algorithme Q-Learning.

## ğŸ¯ Objectif

ImplÃ©menter une version du jeu Snake dans laquelle un agent apprend automatiquement Ã  :
- Se dÃ©placer sur une grille
- Manger des pommes
- Ã‰viter les murs et son propre corps
- Maximiser sa rÃ©compense cumulÃ©e

## ğŸ§  ModÃ©lisation RL

### Ã‰tats
L'Ã©tat est reprÃ©sentÃ© par un tuple de 8 Ã©lÃ©ments :
- **Direction du serpent** (0=UP, 1=DOWN, 2=LEFT, 3=RIGHT)
- **Danger devant** (boolÃ©en)
- **Danger Ã  gauche** (boolÃ©en)
- **Danger Ã  droite** (boolÃ©en)
- **Pomme devant** (boolÃ©en)
- **Pomme Ã  gauche** (boolÃ©en)
- **Pomme Ã  droite** (boolÃ©en)
- **Pomme derriÃ¨re** (boolÃ©en)

### Actions
4 actions possibles :
- 0 : UP (â¬†ï¸)
- 1 : DOWN (â¬‡ï¸)
- 2 : LEFT (â¬…ï¸)
- 3 : RIGHT (â¡ï¸)

Le demi-tour immÃ©diat est bloquÃ© pour Ã©viter les collisions instantanÃ©es.

### RÃ©compenses
- **+10** : Le serpent mange une pomme
- **-10** : Le serpent meurt (collision avec mur ou corps)
- **-0.1** : Ã€ chaque pas (encourage l'efficacitÃ©)

## ğŸš€ Installation

### Avec UV (recommandÃ©)

```bash
# Installer UV si nÃ©cessaire
curl -LsSf https://astral.sh/uv/install.sh | sh

# CrÃ©er l'environnement et installer les dÃ©pendances
uv sync

# Activer l'environnement
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows
```

### Avec pip

```bash
pip install -r requirements.txt
```

## ğŸ® Utilisation

### Interface Web (Streamlit)

Lancer l'application web :

```bash
streamlit run src/app.py
```

L'interface propose deux onglets :

#### ğŸ“ Training
- Configurer les paramÃ¨tres d'entraÃ®nement (taille grille, Ã©pisodes, Î±, Î³, Îµ)
- Lancer l'entraÃ®nement avec visualisation de la progression
- Sauvegarder automatiquement l'agent et les rÃ©sultats

#### ğŸ“Š RÃ©sultats
- Visualiser les courbes d'apprentissage (rÃ©compenses, pommes mangÃ©es, epsilon)
- Afficher les statistiques finales
- Rejouer une partie avec l'agent entraÃ®nÃ©

### EntraÃ®nement en ligne de commande

```bash
python src/trainer.py
```

## ğŸ“ Structure du projet

```
snake-machine-learning/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ snake_environment.py    # Environnement du jeu Snake
â”‚   â”œâ”€â”€ q_learning_agent.py     # Agent Q-Learning
â”‚   â”œâ”€â”€ trainer.py              # Script d'entraÃ®nement
â”‚   â””â”€â”€ app.py                  # Interface web Streamlit
â”œâ”€â”€ models/                     # Agents et rÃ©sultats sauvegardÃ©s
â”œâ”€â”€ pyproject.toml             # Configuration UV
â”œâ”€â”€ requirements.txt           # DÃ©pendances pip
â””â”€â”€ README.md
```

## ğŸ§ª ParamÃ¨tres recommandÃ©s

Pour un bon apprentissage :
- **Grille** : 10x10
- **Ã‰pisodes** : 1000-2000
- **Alpha (Î±)** : 0.1
- **Gamma (Î³)** : 0.9
- **Epsilon initial** : 1.0
- **Epsilon min** : 0.01
- **Epsilon decay** : 0.995

## ğŸ“Š RÃ©sultats attendus

AprÃ¨s ~1000 Ã©pisodes, l'agent devrait :
- Manger en moyenne 3-5 pommes par partie
- Ã‰viter efficacement les obstacles
- DÃ©velopper des stratÃ©gies de dÃ©placement intelligentes

## ğŸ› ï¸ Technologies utilisÃ©es

- **Python 3.9+**
- **Streamlit** : Interface web
- **NumPy** : Calculs numÃ©riques
- **Matplotlib** : Visualisation
- **Plotly** : Graphiques interactifs

## ğŸ“ Licence

Ce projet est rÃ©alisÃ© dans un cadre Ã©ducatif.

## ğŸ‘¨â€ğŸ’» Auteur

Projet rÃ©alisÃ© dans le cadre du cours d'apprentissage par renforcement.
